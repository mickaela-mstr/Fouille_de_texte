# Classification de chansons par genre Ã  partir des paroles

Projet de fouille de texte (LZT001 â€“ M1 TAL)
Sorbonne Nouvelle, 2024-2025

## Description

Ce projet a pour objectif de classifier automatiquement des chansons par genre musical (rap, pop, R\&B) en analysant uniquement leurs paroles. Le modÃ¨le ne dispose ni de la musique ni de mÃ©tadonnÃ©es : il se base exclusivement sur le contenu lexical des textes.

Nous avons constituÃ© un corpus Ã©quilibrÃ© de 453 chansons en anglais, puis appliquÃ© des techniques de prÃ©traitement, vectorisation, analyse exploratoire et classification supervisÃ©e Ã  lâ€™aide de la bibliothÃ¨que scikit-learn (et Weka pour comparaison).

---

## Contenu du dÃ©pÃ´t

```
.
â”œâ”€â”€ corpus/                      # Fichiers textes bruts par genre (pop, rap, rnb)
â”œâ”€â”€ resultats_weka/              # Dossier avec les rÃ©sultats de weka
â”œâ”€â”€ resultats_python/
â”‚   â”œâ”€â”€ wordcloud_pop.png        # Nuage de mots du genre pop
â”‚   â”œâ”€â”€ wordcloud_rap.png        # Nuage de mots du genre rap
â”‚   â”œâ”€â”€ wordcloud_rnb.png        # Nuage de mots du genre rnb
â”‚   â”œâ”€â”€ nb.png                   # Matrice de confusion Naive Bayes
â”‚   â”œâ”€â”€ svm.png                  # Matrice de confusion SVM
â”‚   â”œâ”€â”€ rf.png                   # Matrice de confusion Random Forest
â”‚   â”œâ”€â”€ compare_3.png            # Les 3 matrices cÃ´te Ã  cÃ´te
â”‚   â”œâ”€â”€ compare_accuracies.png   # Accuracy des modÃ¨les (GridSearch)
â”‚   â””â”€â”€  compare_random_state.png # Accuracy moyenne Â± Ã©cart-type (multi-runs)
â”œâ”€â”€ tableaux/
â”‚   â”œâ”€â”€ resultats_gridsearch.csv
â”‚   â”œâ”€â”€ perf_modeles.csv
â”‚   â””â”€â”€ lyrics.csv               # Corpus nettoyÃ© prÃªt Ã  Ãªtre utilisÃ©
â”œâ”€â”€ scripts/
    â”œâ”€â”€ shuffle_and_split.py
â”‚   â”œâ”€â”€ recup_paroles.py         # RÃ©cupÃ©ration des paroles (API Genius)
â”‚   â”œâ”€â”€ data_prep.py             # Nettoyage + gÃ©nÃ©ration de lyrics.csv
â”‚   â”œâ”€â”€ nuage_mot.py             # Wordclouds par genre
â”‚   â”œâ”€â”€ algo.py                  # Classification + GridSearch + Ã©valuation
â”‚   â”œâ”€â”€ plot_scores.py           # Comparaison des accuracies (barplot)
â”‚   â””â”€â”€ plot_random_state.py     # Barplot avec erreurs (multi-runs)
â”œâ”€â”€ Rapport Fouille de texte.pdf
â””â”€â”€ README.md

```

---

## ðŸš€ Lancer une classification

Lancer le script principal de classification (avec GridSearchCV + Ã©valuation) :

```bash
python3 scripts/algo.py
```

---

## RÃ©sultats

* SVM (noyau linÃ©aire) obtient les meilleurs rÃ©sultats globaux avec une accuracy de 66â€¯%.
* Naive Bayes et Random Forest atteignent environ 60â€¯%, avec des comportements trÃ¨s diffÃ©rents :

  * Naive Bayes est plus stable mais confond pop et R\&B.
  * Random Forest distingue bien rap et R\&B mais Ã©choue sur la pop.
* Le genre rap est plus facilement identifiable, tandis que pop et R\&B sont lexicalement trÃ¨s proches.
* Les rÃ©sultats sont confirmÃ©s par :

  * les matrices de confusion,
  * les rapports de classification,
  * les graphes de performance,
  * et les nuages de mots.

---

## Bibliographie

* [Scikit-learn Documentation](https://scikit-learn.org/stable/)
* [Genius API Docs](https://docs.genius.com/)
* [Weka Wiki](https://waikato.github.io/weka-wiki/)
* Cours "Introduction Ã  la fouille de texte" â€“ Yoann Dupont / Isabelle Tellier & LoÃ¯c Grobol

---

## Auteurs

* InÃ¨s Martins â€” [GitHub](https://github.com/Inesmartins1912)
* MickaÃ«la Mastrodicasa â€” [GitHub](https://github.com/mickaela-mstr)
* Jourdan Wilson â€” [GitHub](https://github.com/jourdanwilson)
